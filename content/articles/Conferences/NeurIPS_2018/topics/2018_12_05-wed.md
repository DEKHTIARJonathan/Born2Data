Title: NeurIPS 2018 - Research Log
HeadTitle: NeurIPS 2018 - Research Log
Date: 2018-12-03 10:15
Category: Deep Learning
Tags: Deep Learning, Research, Statistics, Computer Vision, NLP, NIPS, NeurIPS
Slug: NeurIPS_2018/topics/2018_12_05-wed
Author: Jonathan DEKHTIAR
Headline: A condensed research review of the talks and poster sessions I attended.
Status: draft

# Wednesday 05 December 2018
--------------------

### 1. Variance-Reduced Stochastic Gradient Descent on Streaming Data

**Link to paper:** <https://papers.nips.cc/paper/8196-variance-reduced-stochastic-gradient-descent-on-streaming-data>

----------------------

### 2. Understanding Weight Normalized Deep Neural Networks with Rectified Linear Units

**Link to paper:** <https://arxiv.org/abs/1810.01877>

----------------------

### 3. Learning Sparse Neural Networks via Sensitivity-Driven Regularization

**Link to paper:** <https://arxiv.org/abs/1810.11764>

----------------------

### 4. DropBlock: A regularization method for convolutional networks

**Link to paper:** <https://arxiv.org/abs/1810.12890>

**Unofficial Implementation 1 (TF):** <https://github.com/DHZS/tf-dropblock>

**Unofficial Implementation 2 (PyT):** <https://github.com/miguelvr/dropblock>

**Unofficial Implementation 3 (PyT):** <https://github.com/Randl/DropBlock-pytorch>

**Unofficial Implementation 4 (PyT):** <https://github.com/darkknightzh/DropBlock_pytorch>

----------------------

### 5. Simple, Distributed, and Accelerated Probabilistic Programming - Google AI

**Link to paper:** <https://arxiv.org/abs/1811.02091>

----------------------

### 6. Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming - Google AI

**Link to paper:** <https://arxiv.org/abs/1809.09569>

**Github Repo:** <https://github.com/google/tangent>

----------------------

### 7. On the Local Hessian in Back-propagation - Microsoft

**Link to paper:** <https://papers.nips.cc/paper/7887-on-the-local-hessian-in-back-propagation>

----------------------

### 8. Neural Arithmetic Logic Units - DeepMind

**Link to paper:** <https://arxiv.org/abs/1808.00508>

**Github Repo:** <https://github.com/ahylton19/simpleNALU-tf>

**TF Blog Post:** <https://medium.com/tensorflow/understanding-neural-arithmetic-logic-units-11b0f85c1d1d>

Numerous third party blog posts are available on that one.

**Blog Post 1:** <https://medium.com/mlreview/simple-guide-to-neural-arithmetic-logic-units-nalu-explanation-intuition-and-code-64bc22605712>

**Blog Post 2:** <https://medium.com/analytics-vidhya/neural-arithmetic-logic-units-nalu-a-new-beginning-9b9b8a69eb32>

**Blog Post 3:** <https://sergioskar.github.io/NALU/>

**Youtube Video by Siraj:** <https://www.youtube.com/watch?v=v9E7Wg0dHiU>

----------------------

### 9. Porcupine Neural Networks: Approximating Neural Network Landscapes

**Link to paper:** <https://papers.nips.cc/paper/7732-porcupine-neural-networks-approximating-neural-network-landscapes>

----------------------

### 10. Adding One Neuron Can Eliminate All Bad Local Minima

**Link to paper:** <https://arxiv.org/abs/1805.08671>

**Unofficial Summary:** <https://www.techleer.com/articles/526-adding-one-neuron-can-eliminate-all-bad-local-minima/>

**Unofficial blog post:** <https://rossum.ai/blog/2018/07/22/does-adding-one-neuron-help-real-world-networks/>

----------------------

### 10. Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects

**Link to paper:** <https://arxiv.org/abs/1806.01794>

**Github Repository:** <https://github.com/akosiorek/sqair>

----------------------

### 11. Sanity Checks for Saliency Maps

**Link to paper:** <https://arxiv.org/abs/1810.03292>

----------------------

### 12. Sparsified SGD with memory

**Link to paper:** <https://arxiv.org/abs/1809.07599>

----------------------

### 13. ATOMO: Communication-efficient Learning via Atomic Sparsification

**Link to paper:** <https://arxiv.org/abs/1806.04090>

----------------------

### 14. Dimensionality Reduction has Quantifiable Imperfections: Two Geometric Bounds

**Link to paper:** <https://arxiv.org/abs/1811.00115>

**Blog Post (FR):** <https://www.borealisai.com/fr/blogue/la-reduction-de-la-dimensionnalite-comporte-des-imperfections-quantifiables/>

----------------------

### 15. Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation

**Link to paper:** <https://papers.nips.cc/paper/7313-deep-non-blind-deconvolution-via-generalized-low-rank-approximation>

----------------------

### 16. A loss framework for calibrated anomaly detection

**Link to paper:** <https://papers.nips.cc/paper/7422-a-loss-framework-for-calibrated-anomaly-detection>

----------------------

### 17. How to Start Training: The Effect of Initialization and Architecture

**Link to paper:** <https://arxiv.org/abs/1803.01719>

----------------------

### 18. A Probabilistic U-Net for Segmentation of Ambiguous Images

**Link to paper:** <https://arxiv.org/abs/1806.05034>

**Github Repository:** <https://github.com/MIC-DKFZ/probabilistic_unet>

----------------------

### 19. Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training

**Link to paper:** <https://arxiv.org/abs/1811.03619>

----------------------

### 20. Sublinear Time Low-Rank Approximation of Distance Matrices

**Link to paper:** <https://arxiv.org/abs/1809.06986>

----------------------

### 21. Legendre Decomposition for Tensors

**Link to paper:** <https://arxiv.org/abs/1802.04502>

**Youtube Video (2min):** <https://www.youtube.com/watch?v=CHVZp8KnvzY>

----------------------

### 22. Scalable Laplacian K-modes

**Link to paper:** <https://papers.nips.cc/paper/8208-scalable-laplacian-k-modes>

**Github Repository:** <https://github.com/imtiazziko/SLK>

**Youtube Video (3min):** <https://www.youtube.com/watch?v=a4DwNoWkN40>

----------------------

### 23. Reducing Network Agnostophobia

**Link to paper:** <https://arxiv.org/abs/1811.04110>

**Github Repository:** <https://github.com/Vastlab/Reducing-Network-Agnostophobia>

----------------------

### 24. The Physical Systems Behind Optimization Algorithms

**Link to paper:** <https://arxiv.org/abs/1612.02803>

----------------------

### 25. Benefits of over-parameterization with EM

**Link to paper:** <https://arxiv.org/abs/1810.11344>

----------------------

### 26. Model-based targeted dimensionality reduction for neuronal population data

**Link to paper:** <http://papers.nips.cc/paper/7903-model-based-targeted-dimensionality-reduction-for-neuronal-population-data>

Open Source project soon to be released

----------------------

### 27. Structured Local Optima in Sparse Blind Deconvolution

**Link to paper:** <https://arxiv.org/abs/1806.00338>

----------------------

### 28. Are ResNets Provably Better than Linear Predictors?

**Link to paper:** <https://arxiv.org/abs/1804.06739>

----------------------

### 29. GILBO: One Metric to Measure Them All

**Link to paper:** <https://arxiv.org/abs/1802.04874>

----------------------

### 30. Distributed Stochastic Optimization via Adaptive SGD

**Link to paper:** <https://arxiv.org/abs/1802.05811>

----------------------

### 31. The Effect of Network Width on the Performance of Large-batch Training

**Link to paper:** <https://arxiv.org/abs/1806.03791>

----------------------

### 32. GPytorch: Blackbox matrix-matrix gaussian process inference with GPU acceleration

**Link to paper:** <https://arxiv.org/abs/1809.11165>

**Github Repository:** <https://github.com/cornellius-gp/gpytorch>

**Official Website:** <https://gpytorch.ai/>

=====================================================================

----------------------

### 666.

**Link to paper:** <>

**Blog Post:** <>

**Github Repo:** <>
